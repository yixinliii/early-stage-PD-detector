{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dropout, Flatten, Convolution1D as Conv1D, Convolution2D as Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional, Input\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import MaxPooling1D, AveragePooling1D, BatchNormalization as BatchNorm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anony\\Desktop\\final\\keyboard\\code\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "filename = '/encoding_A_freq100_chunks200.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (61696,)\n",
      "Train shape (61696, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# h5f = h5py.File(path + filename,'r')\n",
    "# X_train = h5f['train'][:]\n",
    "# Y_train = h5f['target'][:]\n",
    "# X_test = h5f['test'][:]\n",
    "# Y_test = h5f['target_test'][:]\n",
    "# h5f.close()\n",
    "\n",
    "# print('Target shape', Y_train.shape)\n",
    "# print('Train shape', X_train.shape)\n",
    "# print('Target test shape', Y_test.shape)\n",
    "# print('Test shape', X_test.shape)\n",
    "\n",
    "h5f = h5py.File(path + filename,'r')\n",
    "X_train = h5f['train'][:]\n",
    "Y_train = h5f['target'][:]\n",
    "h5f.close()\n",
    "\n",
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend train set by flipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (123392,)\n",
      "Train shape (123392, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "extend_x = np.flip(X_train, axis=1)\n",
    "extend_y = Y_train\n",
    "\n",
    "X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "\n",
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)\n",
    "# print('Target test shape', Y_test.shape)\n",
    "# print('Test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model - Inception with different kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /lyceum/ao2u17/.conda/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 32)      992         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 32)      1312        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 500, 32)      1632        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 500, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 500, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 500, 32)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 64)      61504       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 500, 64)      81984       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 500, 64)      102464      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 500, 64)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 500, 64)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 500, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 192)     0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 192)     768         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 500, 192)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 17, 192)      0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3264)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          417920      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 668,705\n",
      "Trainable params: 668,321\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 22596 samples, validate on 3988 samples\n",
      "Epoch 1/30\n",
      "22596/22596 [==============================] - 11s 486us/step - loss: 1.3299 - binary_accuracy: 0.6007 - val_loss: 0.6794 - val_binary_accuracy: 0.6021\n",
      "Epoch 2/30\n",
      "22596/22596 [==============================] - 8s 341us/step - loss: 0.6298 - binary_accuracy: 0.6459 - val_loss: 0.6268 - val_binary_accuracy: 0.6647\n",
      "Epoch 3/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.6052 - binary_accuracy: 0.6567 - val_loss: 0.6492 - val_binary_accuracy: 0.6399\n",
      "Epoch 4/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5964 - binary_accuracy: 0.6648 - val_loss: 0.6166 - val_binary_accuracy: 0.6652\n",
      "Epoch 5/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5929 - binary_accuracy: 0.6685 - val_loss: 0.6875 - val_binary_accuracy: 0.5840\n",
      "Epoch 6/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5865 - binary_accuracy: 0.6730 - val_loss: 0.6633 - val_binary_accuracy: 0.6254\n",
      "Epoch 7/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5815 - binary_accuracy: 0.6771 - val_loss: 0.6239 - val_binary_accuracy: 0.6527\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "### Alternative model - 2 conv layers\n",
    "np.random.seed(14)  # fix the random numbers generator state\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "# sgd = SGD(lr=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(input_shape=input_shape, filters=64, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Conv1D(filters=128, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(MaxPooling1D(pool_size=pool_size, strides=strides))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Dense(128))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "# model.add(Dense(nb_classes))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "\n",
    "tower_1 = Conv1D(filters=32, kernel_size=30, padding='same')(inp)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Conv1D(filters=64, kernel_size=30, padding='same')(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "\n",
    "tower_2 = Conv1D(filters=32, kernel_size=40, padding='same')(inp)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Conv1D(filters=64, kernel_size=40, padding='same')(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "\n",
    "tower_3 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "middle = BatchNorm()(middle)\n",
    "middle = LeakyReLU(alpha=0.01)(middle)\n",
    "middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "middle = Flatten()(middle)\n",
    "\n",
    "out = Dense(128, activation='linear')(middle)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping], \n",
    "                   validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6327608982826949\n",
      "AUC is 0.6974089475769089\n",
      "F1-score is 0.5716486902927581\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print('Accuracy is', accuracy_score(Y_test, np.round(Y_pred)))\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "print('AUC is', AUC)\n",
    "f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "print('F1-score is', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Y_pred)\n",
    "# Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception with dilated units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 200, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 200, 16)      816         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 200, 32)      1632        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 200, 16)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 200, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 200, 16)      0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 200, 32)      0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 200, 64)      3264        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 200, 16)      12816       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 200, 32)      51232       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 200, 64)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 200, 16)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 200, 32)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 200, 64)      0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 200, 16)      0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 200, 32)      0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 200, 64)      204864      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 200, 16)      12816       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 200, 32)      51232       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 200, 64)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 200, 16)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 200, 32)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 200, 64)      204864      leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 200, 16)      0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 200, 32)      0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 200, 64)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200, 112)     0           dropout_11[0][0]                 \n",
      "                                                                 dropout_14[0][0]                 \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 112)     448         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 200, 112)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 7, 112)       0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 784)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 784)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          100480      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 644,593\n",
      "Trainable params: 644,369\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 104883 samples, validate on 18509 samples\n",
      "Epoch 1/30\n",
      "104883/104883 [==============================] - 33s 317us/step - loss: 0.6501 - binary_accuracy: 0.6120 - val_loss: 0.6635 - val_binary_accuracy: 0.6146\n",
      "Epoch 2/30\n",
      "104883/104883 [==============================] - 31s 299us/step - loss: 0.6308 - binary_accuracy: 0.6260 - val_loss: 0.6492 - val_binary_accuracy: 0.6370\n",
      "Epoch 3/30\n",
      "104883/104883 [==============================] - 31s 292us/step - loss: 0.6282 - binary_accuracy: 0.6267 - val_loss: 0.6447 - val_binary_accuracy: 0.6346\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104883/104883 [==============================] - 30s 288us/step - loss: 0.6250 - binary_accuracy: 0.6310 - val_loss: 0.6805 - val_binary_accuracy: 0.5769- loss: 0.6262 - binary_accuracy: 0 - ETA: 9s - lo - ETA: 1s - loss: 0.6249 - binary_accuracy - ETA: 1s - loss: 0.62\n",
      "Epoch 5/30\n",
      "104883/104883 [==============================] - 30s 284us/step - loss: 0.6227 - binary_accuracy: 0.6316 - val_loss: 0.6394 - val_binary_accuracy: 0.6386\n",
      "Epoch 6/30\n",
      "104883/104883 [==============================] - 30s 285us/step - loss: 0.6205 - binary_accuracy: 0.6344 - val_loss: 0.6404 - val_binary_accuracy: 0.6271\n",
      "Epoch 7/30\n",
      "104883/104883 [==============================] - 30s 287us/step - loss: 0.6178 - binary_accuracy: 0.6373 - val_loss: 0.6502 - val_binary_accuracy: 0.6254\n",
      "Epoch 8/30\n",
      "104883/104883 [==============================] - 30s 286us/step - loss: 0.6161 - binary_accuracy: 0.6399 - val_loss: 0.6404 - val_binary_accuracy: 0.6366ss: 0.6169 - bi - ETA: 6s - loss:  - ETA: 4s \n",
      "Epoch 9/30\n",
      "104883/104883 [==============================] - 30s 286us/step - loss: 0.6128 - binary_accuracy: 0.6416 - val_loss: 0.6437 - val_binary_accuracy: 0.6383 0.610 - ETA: 9s - - ETA: 7s - loss: 0.6117 - binary_accuracy: 0.64 - ETA: 6s - loss: 0 - ETA: 5s - l - ETA: 3s - loss: 0.6124 - bin - ETA: 2s - loss: 0.6124 -  - ETA: 1s - loss: 0.6125 - bi\n",
      "Epoch 10/30\n",
      "104883/104883 [==============================] - 30s 286us/step - loss: 0.6096 - binary_accuracy: 0.6451 - val_loss: 0.6451 - val_binary_accuracy: 0.6527\n",
      "Epoch 11/30\n",
      "104883/104883 [==============================] - 30s 287us/step - loss: 0.6063 - binary_accuracy: 0.6492 - val_loss: 0.6580 - val_binary_accuracy: 0.5592\n",
      "Epoch 12/30\n",
      "104883/104883 [==============================] - 30s 286us/step - loss: 0.6029 - binary_accuracy: 0.6523 - val_loss: 0.6606 - val_binary_accuracy: 0.6048\n",
      "Epoch 13/30\n",
      "104883/104883 [==============================] - 30s 287us/step - loss: 0.5987 - binary_accuracy: 0.6564 - val_loss: 0.6440 - val_binary_accuracy: 0.6306\n",
      "Epoch 14/30\n",
      "104883/104883 [==============================] - 30s 287us/step - loss: 0.5928 - binary_accuracy: 0.6625 - val_loss: 0.6545 - val_binary_accuracy: 0.6163loss: 0.5928 - binar - ETA: 2s - loss: 0.593 - ETA: 1s - loss: 0.59\n",
      "Epoch 15/30\n",
      "104883/104883 [==============================] - 31s 294us/step - loss: 0.5871 - binary_accuracy: 0.6670 - val_loss: 0.6653 - val_binary_accuracy: 0.5451 - loss: 0.5868 - binary_ac\n",
      "Epoch 16/30\n",
      "104883/104883 [==============================] - 30s 290us/step - loss: 0.5803 - binary_accuracy: 0.6729 - val_loss: 0.6469 - val_binary_accuracy: 0.6400\n",
      "Epoch 17/30\n",
      "104883/104883 [==============================] - 30s 288us/step - loss: 0.5726 - binary_accuracy: 0.6790 - val_loss: 0.6737 - val_binary_accuracy: 0.5494a - ETA:  - ETA: 1s - loss: - ETA: 0s - loss: 0.5726 - binary_accuracy: 0.679\n",
      "Epoch 18/30\n",
      "104883/104883 [==============================] - 30s 289us/step - loss: 0.5630 - binary_accuracy: 0.6853 - val_loss: 0.6580 - val_binary_accuracy: 0.6219 loss:\n",
      "Epoch 19/30\n",
      "104883/104883 [==============================] - 30s 290us/step - loss: 0.5531 - binary_accuracy: 0.6931 - val_loss: 0.6966 - val_binary_accuracy: 0.5920\n",
      "Epoch 20/30\n",
      "104883/104883 [==============================] - 30s 288us/step - loss: 0.5418 - binary_accuracy: 0.7004 - val_loss: 0.6757 - val_binary_accuracy: 0.6465\n",
      "Epoch 21/30\n",
      "104883/104883 [==============================] - 30s 282us/step - loss: 0.5306 - binary_accuracy: 0.7084 - val_loss: 0.8396 - val_binary_accuracy: 0.4672A: 1s - loss: 0.5300 - binary_accuracy: 0.70 - ETA: 1s - loss: 0.5300\n",
      "Epoch 22/30\n",
      "104883/104883 [==============================] - 29s 280us/step - loss: 0.5183 - binary_accuracy: 0.7166 - val_loss: 0.7312 - val_binary_accuracy: 0.5199\n",
      "Epoch 23/30\n",
      "104883/104883 [==============================] - 30s 290us/step - loss: 0.5047 - binary_accuracy: 0.7259 - val_loss: 0.6871 - val_binary_accuracy: 0.6358\n",
      "Epoch 24/30\n",
      "104883/104883 [==============================] - 30s 287us/step - loss: 0.4905 - binary_accuracy: 0.7350 - val_loss: 0.7052 - val_binary_accuracy: 0.6403\n",
      "Epoch 25/30\n",
      "104883/104883 [==============================] - 31s 294us/step - loss: 0.4747 - binary_accuracy: 0.7445 - val_loss: 0.8939 - val_binary_accuracy: 0.4618\n",
      "Epoch 26/30\n",
      "104883/104883 [==============================] - 30s 288us/step - loss: 0.4589 - binary_accuracy: 0.7534 - val_loss: 0.7812 - val_binary_accuracy: 0.5221\n",
      "Epoch 27/30\n",
      "104883/104883 [==============================] - 30s 287us/step - loss: 0.4447 - binary_accuracy: 0.7604 - val_loss: 0.8500 - val_binary_accuracy: 0.4994\n",
      "Epoch 28/30\n",
      "104883/104883 [==============================] - 30s 290us/step - loss: 0.4283 - binary_accuracy: 0.7690 - val_loss: 0.8765 - val_binary_accuracy: 0.4915\n",
      "Epoch 29/30\n",
      "104883/104883 [==============================] - 30s 283us/step - loss: 0.4153 - binary_accuracy: 0.7763 - val_loss: 0.8357 - val_binary_accuracy: 0.5227\n",
      "Epoch 30/30\n",
      "104883/104883 [==============================] - 30s 288us/step - loss: 0.4014 - binary_accuracy: 0.7835 - val_loss: 0.8019 - val_binary_accuracy: 0.6257\n"
     ]
    }
   ],
   "source": [
    "### Alternative model - 2 conv layers\n",
    "np.random.seed(14)  # fix the random numbers generator state\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "# sgd = SGD(lr=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(input_shape=input_shape, filters=64, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Conv1D(filters=128, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(MaxPooling1D(pool_size=pool_size, strides=strides))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Dense(128))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "# model.add(Dense(nb_classes))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "\n",
    "tower_1 = Conv1D(filters=16, kernel_size=50, padding='same')(inp)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=2)(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=3)(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "tower_2 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=2)(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=3)(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(inp)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "tower_3 = Dropout(dropout)(tower_3)\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=2)(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=3)(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "middle = BatchNorm()(middle)\n",
    "middle = LeakyReLU(alpha=0.01)(middle)\n",
    "middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "middle = Flatten()(middle)\n",
    "middle = Dropout(dropout)(middle)\n",
    "\n",
    "out = Dense(128, activation='linear')(middle)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='sgd')  # was adam (rmsprop alternative)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-76ab050b6deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy is'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mAUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC is'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print('Accuracy is', accuracy_score(Y_test, np.round(Y_pred)))\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "print('AUC is', AUC)\n",
    "f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "print('F1-score is', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation - Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\Anony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Anony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 200, 16)      816         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 200, 32)      1632        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 200, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 200, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200, 16)      0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200, 32)      0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 64)      3264        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 200, 16)      12816       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 200, 32)      51232       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 200, 64)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 200, 16)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 200, 32)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 200, 64)      0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200, 16)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 200, 32)      0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 200, 64)      204864      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 200, 16)      12816       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 200, 32)      51232       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 200, 64)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 200, 16)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 200, 32)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 200, 64)      204864      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200, 16)      0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 200, 32)      0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 200, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 112)     0           dropout_3[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 112)     448         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 200, 112)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 7, 112)       0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 784)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          100480      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 644,593\n",
      "Trainable params: 644,369\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "WARNING:tensorflow:From C:\\Users\\Anony\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 188788 samples, validate on 33316 samples\n",
      "Epoch 1/30\n",
      "  4864/188788 [..............................] - ETA: 17:58 - loss: 1.0372 - binary_accuracy: 0.5362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-422744518c17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n\u001b[1;32m---> 87\u001b[1;33m                         validation_split=0.15)\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "f1_list = []\n",
    "loss = []\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train = Y[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # added flip of the training data\n",
    "    extend_x = np.flip(X_train, axis=1)\n",
    "    extend_y = Y_train\n",
    "\n",
    "    X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "    Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "    \n",
    "    print('Build model...')\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same')(inp)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=2)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=3)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=2)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=3)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(inp)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Dropout(dropout)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=2)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=3)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "    middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "    middle = BatchNorm()(middle)\n",
    "    middle = LeakyReLU(alpha=0.01)(middle)\n",
    "    middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "    middle = Flatten()(middle)\n",
    "    middle = Dropout(dropout)(middle)\n",
    "\n",
    "    out = Dense(128, activation='linear')(middle)\n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Train...\")\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                        validation_split=0.15)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, np.round(Y_pred))\n",
    "    print('Accuracy is', acc)\n",
    "    AUC = roc_auc_score(Y_test, Y_pred)\n",
    "    print('AUC is', AUC)\n",
    "    f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "    print('F1-score is', f1)\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    AUC_list.append(AUC)\n",
    "    f1_list.append(f1)\n",
    "    loss.append(np.mean(history.history['val_loss']))\n",
    "    \n",
    "print('Accuracy: ', np.mean(acc_list)*100)\n",
    "print('AUC: ', np.mean(AUC_list))\n",
    "print('f1-score: ', np.mean(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation - dilated Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_62 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_550 (Conv1D)             (None, 500, 16)      816         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_553 (Conv1D)             (None, 500, 32)      1632        input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_611 (LeakyReLU)     (None, 500, 16)      0           conv1d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_614 (LeakyReLU)     (None, 500, 32)      0           conv1d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_489 (Dropout)           (None, 500, 16)      0           leaky_re_lu_611[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_492 (Dropout)           (None, 500, 32)      0           leaky_re_lu_614[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_556 (Conv1D)             (None, 500, 64)      3264        input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_551 (Conv1D)             (None, 500, 16)      12816       dropout_489[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_554 (Conv1D)             (None, 500, 32)      51232       dropout_492[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_617 (LeakyReLU)     (None, 500, 64)      0           conv1d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_612 (LeakyReLU)     (None, 500, 16)      0           conv1d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_615 (LeakyReLU)     (None, 500, 32)      0           conv1d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_495 (Dropout)           (None, 500, 64)      0           leaky_re_lu_617[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_490 (Dropout)           (None, 500, 16)      0           leaky_re_lu_612[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_493 (Dropout)           (None, 500, 32)      0           leaky_re_lu_615[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_557 (Conv1D)             (None, 500, 64)      204864      dropout_495[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_552 (Conv1D)             (None, 500, 16)      12816       dropout_490[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_555 (Conv1D)             (None, 500, 32)      51232       dropout_493[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_618 (LeakyReLU)     (None, 500, 64)      0           conv1d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_613 (LeakyReLU)     (None, 500, 16)      0           conv1d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_616 (LeakyReLU)     (None, 500, 32)      0           conv1d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_558 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_618[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_491 (Dropout)           (None, 500, 16)      0           leaky_re_lu_613[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_494 (Dropout)           (None, 500, 32)      0           leaky_re_lu_616[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_619 (LeakyReLU)     (None, 500, 64)      0           conv1d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 500, 112)     0           dropout_491[0][0]                \n",
      "                                                                 dropout_494[0][0]                \n",
      "                                                                 leaky_re_lu_619[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 500, 112)     448         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_620 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_620[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_62 (Flatten)            (None, 1904)         0           max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_496 (Dropout)           (None, 1904)         0           flatten_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 128)          243840      dropout_496[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 1)            129         dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 11325 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11325/11325 [==============================] - 21s 2ms/step - loss: 1.7766 - binary_accuracy: 0.5533 - val_loss: 0.8751 - val_binary_accuracy: 0.3612\n",
      "Epoch 2/30\n",
      "11325/11325 [==============================] - 6s 570us/step - loss: 0.7209 - binary_accuracy: 0.6205 - val_loss: 0.9394 - val_binary_accuracy: 0.6398\n",
      "Epoch 3/30\n",
      "11325/11325 [==============================] - 6s 573us/step - loss: 0.6414 - binary_accuracy: 0.6475 - val_loss: 0.7491 - val_binary_accuracy: 0.4902\n",
      "Epoch 4/30\n",
      "11325/11325 [==============================] - 6s 573us/step - loss: 0.6365 - binary_accuracy: 0.6565 - val_loss: 0.9351 - val_binary_accuracy: 0.5633\n",
      "Epoch 5/30\n",
      "11325/11325 [==============================] - 7s 575us/step - loss: 0.6050 - binary_accuracy: 0.6755 - val_loss: 0.6802 - val_binary_accuracy: 0.5843\n",
      "Epoch 6/30\n",
      "11325/11325 [==============================] - 6s 573us/step - loss: 0.5923 - binary_accuracy: 0.6783 - val_loss: 0.7595 - val_binary_accuracy: 0.4707\n",
      "Epoch 7/30\n",
      "11325/11325 [==============================] - 7s 576us/step - loss: 0.5807 - binary_accuracy: 0.6859 - val_loss: 0.7744 - val_binary_accuracy: 0.5693\n",
      "Epoch 8/30\n",
      "11325/11325 [==============================] - 7s 582us/step - loss: 0.5748 - binary_accuracy: 0.6869 - val_loss: 0.7830 - val_binary_accuracy: 0.5848\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6167341430499326\n",
      "AUC is 0.6689541251655038\n",
      "F1-score is 0.4453125\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_559 (Conv1D)             (None, 500, 16)      816         input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_562 (Conv1D)             (None, 500, 32)      1632        input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_621 (LeakyReLU)     (None, 500, 16)      0           conv1d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_624 (LeakyReLU)     (None, 500, 32)      0           conv1d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_497 (Dropout)           (None, 500, 16)      0           leaky_re_lu_621[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_500 (Dropout)           (None, 500, 32)      0           leaky_re_lu_624[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_565 (Conv1D)             (None, 500, 64)      3264        input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_560 (Conv1D)             (None, 500, 16)      12816       dropout_497[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_563 (Conv1D)             (None, 500, 32)      51232       dropout_500[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_627 (LeakyReLU)     (None, 500, 64)      0           conv1d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_622 (LeakyReLU)     (None, 500, 16)      0           conv1d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_625 (LeakyReLU)     (None, 500, 32)      0           conv1d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_503 (Dropout)           (None, 500, 64)      0           leaky_re_lu_627[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_498 (Dropout)           (None, 500, 16)      0           leaky_re_lu_622[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_501 (Dropout)           (None, 500, 32)      0           leaky_re_lu_625[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_566 (Conv1D)             (None, 500, 64)      204864      dropout_503[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_561 (Conv1D)             (None, 500, 16)      12816       dropout_498[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_564 (Conv1D)             (None, 500, 32)      51232       dropout_501[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_628 (LeakyReLU)     (None, 500, 64)      0           conv1d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_623 (LeakyReLU)     (None, 500, 16)      0           conv1d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_626 (LeakyReLU)     (None, 500, 32)      0           conv1d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_567 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_628[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_499 (Dropout)           (None, 500, 16)      0           leaky_re_lu_623[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_502 (Dropout)           (None, 500, 32)      0           leaky_re_lu_626[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_629 (LeakyReLU)     (None, 500, 64)      0           conv1d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 500, 112)     0           dropout_499[0][0]                \n",
      "                                                                 dropout_502[0][0]                \n",
      "                                                                 leaky_re_lu_629[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 500, 112)     448         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_630 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_630[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_63 (Flatten)            (None, 1904)         0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_504 (Dropout)           (None, 1904)         0           flatten_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 128)          243840      dropout_504[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 1)            129         dense_125[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 11325 samples, validate on 1999 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325/11325 [==============================] - 21s 2ms/step - loss: 1.8035 - binary_accuracy: 0.5571 - val_loss: 1.1180 - val_binary_accuracy: 0.3802\n",
      "Epoch 2/30\n",
      "11325/11325 [==============================] - 7s 579us/step - loss: 0.6883 - binary_accuracy: 0.6291 - val_loss: 0.7757 - val_binary_accuracy: 0.4622\n",
      "Epoch 3/30\n",
      "11325/11325 [==============================] - 7s 578us/step - loss: 0.6337 - binary_accuracy: 0.6502 - val_loss: 0.7156 - val_binary_accuracy: 0.6078\n",
      "Epoch 4/30\n",
      "11325/11325 [==============================] - 7s 578us/step - loss: 0.6073 - binary_accuracy: 0.6650 - val_loss: 0.7563 - val_binary_accuracy: 0.4887\n",
      "Epoch 5/30\n",
      "11325/11325 [==============================] - 7s 579us/step - loss: 0.6100 - binary_accuracy: 0.6695 - val_loss: 0.7454 - val_binary_accuracy: 0.5033\n",
      "Epoch 6/30\n",
      "11325/11325 [==============================] - 7s 577us/step - loss: 0.5841 - binary_accuracy: 0.6834 - val_loss: 0.7793 - val_binary_accuracy: 0.5893\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.5391363022941971\n",
      "AUC is 0.5953511412705957\n",
      "F1-score is 0.18593563766388557\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_64 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_568 (Conv1D)             (None, 500, 16)      816         input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_571 (Conv1D)             (None, 500, 32)      1632        input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_631 (LeakyReLU)     (None, 500, 16)      0           conv1d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_634 (LeakyReLU)     (None, 500, 32)      0           conv1d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_505 (Dropout)           (None, 500, 16)      0           leaky_re_lu_631[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_508 (Dropout)           (None, 500, 32)      0           leaky_re_lu_634[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_574 (Conv1D)             (None, 500, 64)      3264        input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_569 (Conv1D)             (None, 500, 16)      12816       dropout_505[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_572 (Conv1D)             (None, 500, 32)      51232       dropout_508[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_637 (LeakyReLU)     (None, 500, 64)      0           conv1d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_632 (LeakyReLU)     (None, 500, 16)      0           conv1d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_635 (LeakyReLU)     (None, 500, 32)      0           conv1d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_511 (Dropout)           (None, 500, 64)      0           leaky_re_lu_637[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_506 (Dropout)           (None, 500, 16)      0           leaky_re_lu_632[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_509 (Dropout)           (None, 500, 32)      0           leaky_re_lu_635[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_575 (Conv1D)             (None, 500, 64)      204864      dropout_511[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_570 (Conv1D)             (None, 500, 16)      12816       dropout_506[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_573 (Conv1D)             (None, 500, 32)      51232       dropout_509[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_638 (LeakyReLU)     (None, 500, 64)      0           conv1d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_633 (LeakyReLU)     (None, 500, 16)      0           conv1d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_636 (LeakyReLU)     (None, 500, 32)      0           conv1d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_576 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_638[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_507 (Dropout)           (None, 500, 16)      0           leaky_re_lu_633[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_510 (Dropout)           (None, 500, 32)      0           leaky_re_lu_636[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_639 (LeakyReLU)     (None, 500, 64)      0           conv1d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 500, 112)     0           dropout_507[0][0]                \n",
      "                                                                 dropout_510[0][0]                \n",
      "                                                                 leaky_re_lu_639[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 500, 112)     448         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_640 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_640[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_64 (Flatten)            (None, 1904)         0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_512 (Dropout)           (None, 1904)         0           flatten_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 128)          243840      dropout_512[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 1)            129         dense_127[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11326/11326 [==============================] - 22s 2ms/step - loss: 1.4871 - binary_accuracy: 0.5885 - val_loss: 1.0863 - val_binary_accuracy: 0.6373\n",
      "Epoch 2/30\n",
      "11326/11326 [==============================] - 7s 579us/step - loss: 0.6808 - binary_accuracy: 0.6336 - val_loss: 0.7751 - val_binary_accuracy: 0.5188\n",
      "Epoch 3/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.6571 - binary_accuracy: 0.6465 - val_loss: 0.7978 - val_binary_accuracy: 0.5618\n",
      "Epoch 4/30\n",
      "11326/11326 [==============================] - 7s 579us/step - loss: 0.6216 - binary_accuracy: 0.6617 - val_loss: 0.7329 - val_binary_accuracy: 0.4682\n",
      "Epoch 5/30\n",
      "11326/11326 [==============================] - 7s 581us/step - loss: 0.5887 - binary_accuracy: 0.6766 - val_loss: 0.8049 - val_binary_accuracy: 0.5568\n",
      "Epoch 6/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.5792 - binary_accuracy: 0.6847 - val_loss: 0.9173 - val_binary_accuracy: 0.5448\n",
      "Epoch 7/30\n",
      "11326/11326 [==============================] - 7s 577us/step - loss: 0.5703 - binary_accuracy: 0.6947 - val_loss: 0.7584 - val_binary_accuracy: 0.4832\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.6495611073598919\n",
      "AUC is 0.723737097421308\n",
      "F1-score is 0.6632057105775471\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_577 (Conv1D)             (None, 500, 16)      816         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_580 (Conv1D)             (None, 500, 32)      1632        input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_641 (LeakyReLU)     (None, 500, 16)      0           conv1d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_644 (LeakyReLU)     (None, 500, 32)      0           conv1d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_513 (Dropout)           (None, 500, 16)      0           leaky_re_lu_641[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_516 (Dropout)           (None, 500, 32)      0           leaky_re_lu_644[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_583 (Conv1D)             (None, 500, 64)      3264        input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_578 (Conv1D)             (None, 500, 16)      12816       dropout_513[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_581 (Conv1D)             (None, 500, 32)      51232       dropout_516[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_647 (LeakyReLU)     (None, 500, 64)      0           conv1d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_642 (LeakyReLU)     (None, 500, 16)      0           conv1d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_645 (LeakyReLU)     (None, 500, 32)      0           conv1d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_519 (Dropout)           (None, 500, 64)      0           leaky_re_lu_647[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_514 (Dropout)           (None, 500, 16)      0           leaky_re_lu_642[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_517 (Dropout)           (None, 500, 32)      0           leaky_re_lu_645[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_584 (Conv1D)             (None, 500, 64)      204864      dropout_519[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_579 (Conv1D)             (None, 500, 16)      12816       dropout_514[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_582 (Conv1D)             (None, 500, 32)      51232       dropout_517[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_648 (LeakyReLU)     (None, 500, 64)      0           conv1d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_643 (LeakyReLU)     (None, 500, 16)      0           conv1d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_646 (LeakyReLU)     (None, 500, 32)      0           conv1d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_585 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_648[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_515 (Dropout)           (None, 500, 16)      0           leaky_re_lu_643[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_518 (Dropout)           (None, 500, 32)      0           leaky_re_lu_646[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_649 (LeakyReLU)     (None, 500, 64)      0           conv1d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 500, 112)     0           dropout_515[0][0]                \n",
      "                                                                 dropout_518[0][0]                \n",
      "                                                                 leaky_re_lu_649[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 500, 112)     448         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_650 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_650[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_65 (Flatten)            (None, 1904)         0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_520 (Dropout)           (None, 1904)         0           flatten_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 128)          243840      dropout_520[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 1)            129         dense_129[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11326/11326 [==============================] - 22s 2ms/step - loss: 2.1902 - binary_accuracy: 0.5462 - val_loss: 0.7107 - val_binary_accuracy: 0.6193\n",
      "Epoch 2/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.6934 - binary_accuracy: 0.6214 - val_loss: 0.9256 - val_binary_accuracy: 0.3442\n",
      "Epoch 3/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.6474 - binary_accuracy: 0.6413 - val_loss: 0.6609 - val_binary_accuracy: 0.5833\n",
      "Epoch 4/30\n",
      "11326/11326 [==============================] - 7s 581us/step - loss: 0.6378 - binary_accuracy: 0.6535 - val_loss: 0.7566 - val_binary_accuracy: 0.5858\n",
      "Epoch 5/30\n",
      "11326/11326 [==============================] - 6s 567us/step - loss: 0.6082 - binary_accuracy: 0.6703 - val_loss: 0.7072 - val_binary_accuracy: 0.4887\n",
      "Epoch 6/30\n",
      "11326/11326 [==============================] - 6s 560us/step - loss: 0.5938 - binary_accuracy: 0.6743 - val_loss: 0.8520 - val_binary_accuracy: 0.4157\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.5408507765023632\n",
      "AUC is 0.5728106649159281\n",
      "F1-score is 0.4910179640718564\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_66 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_586 (Conv1D)             (None, 500, 16)      816         input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_589 (Conv1D)             (None, 500, 32)      1632        input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_651 (LeakyReLU)     (None, 500, 16)      0           conv1d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_654 (LeakyReLU)     (None, 500, 32)      0           conv1d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_521 (Dropout)           (None, 500, 16)      0           leaky_re_lu_651[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_524 (Dropout)           (None, 500, 32)      0           leaky_re_lu_654[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_592 (Conv1D)             (None, 500, 64)      3264        input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_587 (Conv1D)             (None, 500, 16)      12816       dropout_521[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_590 (Conv1D)             (None, 500, 32)      51232       dropout_524[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_657 (LeakyReLU)     (None, 500, 64)      0           conv1d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_652 (LeakyReLU)     (None, 500, 16)      0           conv1d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_655 (LeakyReLU)     (None, 500, 32)      0           conv1d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_527 (Dropout)           (None, 500, 64)      0           leaky_re_lu_657[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_522 (Dropout)           (None, 500, 16)      0           leaky_re_lu_652[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_525 (Dropout)           (None, 500, 32)      0           leaky_re_lu_655[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_593 (Conv1D)             (None, 500, 64)      204864      dropout_527[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_588 (Conv1D)             (None, 500, 16)      12816       dropout_522[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_591 (Conv1D)             (None, 500, 32)      51232       dropout_525[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_658 (LeakyReLU)     (None, 500, 64)      0           conv1d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_653 (LeakyReLU)     (None, 500, 16)      0           conv1d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_656 (LeakyReLU)     (None, 500, 32)      0           conv1d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_594 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_658[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_523 (Dropout)           (None, 500, 16)      0           leaky_re_lu_653[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_526 (Dropout)           (None, 500, 32)      0           leaky_re_lu_656[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_659 (LeakyReLU)     (None, 500, 64)      0           conv1d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 500, 112)     0           dropout_523[0][0]                \n",
      "                                                                 dropout_526[0][0]                \n",
      "                                                                 leaky_re_lu_659[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 500, 112)     448         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_660 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_660[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_66 (Flatten)            (None, 1904)         0           max_pooling1d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_528 (Dropout)           (None, 1904)         0           flatten_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 128)          243840      dropout_528[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 1)            129         dense_131[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 22s 2ms/step - loss: 2.3131 - binary_accuracy: 0.5465 - val_loss: 1.0552 - val_binary_accuracy: 0.6048\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 6s 560us/step - loss: 0.7168 - binary_accuracy: 0.6234 - val_loss: 0.7172 - val_binary_accuracy: 0.6243\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 6s 557us/step - loss: 0.6280 - binary_accuracy: 0.6535 - val_loss: 0.7157 - val_binary_accuracy: 0.5088\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 6s 558us/step - loss: 0.6043 - binary_accuracy: 0.6642 - val_loss: 0.7304 - val_binary_accuracy: 0.5678\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 6s 559us/step - loss: 0.5874 - binary_accuracy: 0.6785 - val_loss: 0.7607 - val_binary_accuracy: 0.5663\n",
      "Epoch 00005: early stopping\n",
      "Accuracy is 0.6547297297297298\n",
      "AUC is 0.7121329437545654\n",
      "F1-score is 0.6362989323843415\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_595 (Conv1D)             (None, 500, 16)      816         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_598 (Conv1D)             (None, 500, 32)      1632        input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_661 (LeakyReLU)     (None, 500, 16)      0           conv1d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_664 (LeakyReLU)     (None, 500, 32)      0           conv1d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_529 (Dropout)           (None, 500, 16)      0           leaky_re_lu_661[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_532 (Dropout)           (None, 500, 32)      0           leaky_re_lu_664[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_601 (Conv1D)             (None, 500, 64)      3264        input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_596 (Conv1D)             (None, 500, 16)      12816       dropout_529[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_599 (Conv1D)             (None, 500, 32)      51232       dropout_532[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_667 (LeakyReLU)     (None, 500, 64)      0           conv1d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_662 (LeakyReLU)     (None, 500, 16)      0           conv1d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_665 (LeakyReLU)     (None, 500, 32)      0           conv1d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_535 (Dropout)           (None, 500, 64)      0           leaky_re_lu_667[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_530 (Dropout)           (None, 500, 16)      0           leaky_re_lu_662[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_533 (Dropout)           (None, 500, 32)      0           leaky_re_lu_665[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_602 (Conv1D)             (None, 500, 64)      204864      dropout_535[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_597 (Conv1D)             (None, 500, 16)      12816       dropout_530[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_600 (Conv1D)             (None, 500, 32)      51232       dropout_533[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_668 (LeakyReLU)     (None, 500, 64)      0           conv1d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_663 (LeakyReLU)     (None, 500, 16)      0           conv1d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_666 (LeakyReLU)     (None, 500, 32)      0           conv1d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_603 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_668[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_531 (Dropout)           (None, 500, 16)      0           leaky_re_lu_663[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_534 (Dropout)           (None, 500, 32)      0           leaky_re_lu_666[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_669 (LeakyReLU)     (None, 500, 64)      0           conv1d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 500, 112)     0           dropout_531[0][0]                \n",
      "                                                                 dropout_534[0][0]                \n",
      "                                                                 leaky_re_lu_669[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 500, 112)     448         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_670 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_670[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 1904)         0           max_pooling1d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_536 (Dropout)           (None, 1904)         0           flatten_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 128)          243840      dropout_536[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 1)            129         dense_133[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 22s 2ms/step - loss: 1.4421 - binary_accuracy: 0.5754 - val_loss: 0.9688 - val_binary_accuracy: 0.6333\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 6s 559us/step - loss: 0.7007 - binary_accuracy: 0.6229 - val_loss: 0.7608 - val_binary_accuracy: 0.6453\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 6s 561us/step - loss: 0.6829 - binary_accuracy: 0.6360 - val_loss: 0.7206 - val_binary_accuracy: 0.5728\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.6238 - binary_accuracy: 0.6554 - val_loss: 0.8904 - val_binary_accuracy: 0.5733\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 6s 560us/step - loss: 0.6035 - binary_accuracy: 0.6657 - val_loss: 0.6825 - val_binary_accuracy: 0.5868\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.5896 - binary_accuracy: 0.6769 - val_loss: 0.7979 - val_binary_accuracy: 0.5628\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.5921 - binary_accuracy: 0.6801 - val_loss: 0.7523 - val_binary_accuracy: 0.5593\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 6s 565us/step - loss: 0.5791 - binary_accuracy: 0.6854 - val_loss: 0.7486 - val_binary_accuracy: 0.4957\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6533783783783784\n",
      "AUC is 0.7156482834185538\n",
      "F1-score is 0.6306695464362851\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_68 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_604 (Conv1D)             (None, 500, 16)      816         input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_607 (Conv1D)             (None, 500, 32)      1632        input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_671 (LeakyReLU)     (None, 500, 16)      0           conv1d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_674 (LeakyReLU)     (None, 500, 32)      0           conv1d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_537 (Dropout)           (None, 500, 16)      0           leaky_re_lu_671[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_540 (Dropout)           (None, 500, 32)      0           leaky_re_lu_674[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_610 (Conv1D)             (None, 500, 64)      3264        input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_605 (Conv1D)             (None, 500, 16)      12816       dropout_537[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_608 (Conv1D)             (None, 500, 32)      51232       dropout_540[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_677 (LeakyReLU)     (None, 500, 64)      0           conv1d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_672 (LeakyReLU)     (None, 500, 16)      0           conv1d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_675 (LeakyReLU)     (None, 500, 32)      0           conv1d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_543 (Dropout)           (None, 500, 64)      0           leaky_re_lu_677[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_538 (Dropout)           (None, 500, 16)      0           leaky_re_lu_672[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_541 (Dropout)           (None, 500, 32)      0           leaky_re_lu_675[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_611 (Conv1D)             (None, 500, 64)      204864      dropout_543[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_606 (Conv1D)             (None, 500, 16)      12816       dropout_538[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_609 (Conv1D)             (None, 500, 32)      51232       dropout_541[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_678 (LeakyReLU)     (None, 500, 64)      0           conv1d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_673 (LeakyReLU)     (None, 500, 16)      0           conv1d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_676 (LeakyReLU)     (None, 500, 32)      0           conv1d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_612 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_678[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_539 (Dropout)           (None, 500, 16)      0           leaky_re_lu_673[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_542 (Dropout)           (None, 500, 32)      0           leaky_re_lu_676[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_679 (LeakyReLU)     (None, 500, 64)      0           conv1d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 500, 112)     0           dropout_539[0][0]                \n",
      "                                                                 dropout_542[0][0]                \n",
      "                                                                 leaky_re_lu_679[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 500, 112)     448         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_680 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_680[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 1904)         0           max_pooling1d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_544 (Dropout)           (None, 1904)         0           flatten_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 128)          243840      dropout_544[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 1)            129         dense_135[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 22s 2ms/step - loss: 1.0808 - binary_accuracy: 0.5766 - val_loss: 0.9084 - val_binary_accuracy: 0.3997\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 6s 560us/step - loss: 0.6821 - binary_accuracy: 0.6225 - val_loss: 0.7271 - val_binary_accuracy: 0.6233\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.6388 - binary_accuracy: 0.6428 - val_loss: 0.6744 - val_binary_accuracy: 0.6098\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 6s 564us/step - loss: 0.6120 - binary_accuracy: 0.6643 - val_loss: 0.7581 - val_binary_accuracy: 0.5673\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 6s 561us/step - loss: 0.5960 - binary_accuracy: 0.6759 - val_loss: 0.8150 - val_binary_accuracy: 0.5638\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 6s 564us/step - loss: 0.5880 - binary_accuracy: 0.6819 - val_loss: 0.9612 - val_binary_accuracy: 0.4592\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6168918918918919\n",
      "AUC is 0.7080204528853178\n",
      "F1-score is 0.6834170854271358\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_613 (Conv1D)             (None, 500, 16)      816         input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_616 (Conv1D)             (None, 500, 32)      1632        input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_681 (LeakyReLU)     (None, 500, 16)      0           conv1d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_684 (LeakyReLU)     (None, 500, 32)      0           conv1d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_545 (Dropout)           (None, 500, 16)      0           leaky_re_lu_681[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_548 (Dropout)           (None, 500, 32)      0           leaky_re_lu_684[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_619 (Conv1D)             (None, 500, 64)      3264        input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_614 (Conv1D)             (None, 500, 16)      12816       dropout_545[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_617 (Conv1D)             (None, 500, 32)      51232       dropout_548[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_687 (LeakyReLU)     (None, 500, 64)      0           conv1d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_682 (LeakyReLU)     (None, 500, 16)      0           conv1d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_685 (LeakyReLU)     (None, 500, 32)      0           conv1d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_551 (Dropout)           (None, 500, 64)      0           leaky_re_lu_687[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_546 (Dropout)           (None, 500, 16)      0           leaky_re_lu_682[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_549 (Dropout)           (None, 500, 32)      0           leaky_re_lu_685[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_620 (Conv1D)             (None, 500, 64)      204864      dropout_551[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_615 (Conv1D)             (None, 500, 16)      12816       dropout_546[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_618 (Conv1D)             (None, 500, 32)      51232       dropout_549[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_688 (LeakyReLU)     (None, 500, 64)      0           conv1d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_683 (LeakyReLU)     (None, 500, 16)      0           conv1d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_686 (LeakyReLU)     (None, 500, 32)      0           conv1d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_621 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_688[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_547 (Dropout)           (None, 500, 16)      0           leaky_re_lu_683[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_550 (Dropout)           (None, 500, 32)      0           leaky_re_lu_686[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_689 (LeakyReLU)     (None, 500, 64)      0           conv1d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 500, 112)     0           dropout_547[0][0]                \n",
      "                                                                 dropout_550[0][0]                \n",
      "                                                                 leaky_re_lu_689[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 500, 112)     448         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_690 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_690[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 1904)         0           max_pooling1d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_552 (Dropout)           (None, 1904)         0           flatten_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 128)          243840      dropout_552[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 1)            129         dense_137[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 23s 2ms/step - loss: 1.8006 - binary_accuracy: 0.5813 - val_loss: 0.7155 - val_binary_accuracy: 0.6608\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 7s 586us/step - loss: 0.7423 - binary_accuracy: 0.6296 - val_loss: 1.3527 - val_binary_accuracy: 0.5463\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 7s 591us/step - loss: 0.6335 - binary_accuracy: 0.6514 - val_loss: 0.6688 - val_binary_accuracy: 0.6183\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 7s 589us/step - loss: 0.6194 - binary_accuracy: 0.6644 - val_loss: 0.6719 - val_binary_accuracy: 0.6278\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.5916 - binary_accuracy: 0.6745 - val_loss: 0.8629 - val_binary_accuracy: 0.4762\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 7s 590us/step - loss: 0.5852 - binary_accuracy: 0.6801 - val_loss: 0.6998 - val_binary_accuracy: 0.5863\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6682432432432432\n",
      "AUC is 0.7462353907962016\n",
      "F1-score is 0.5972108285479902\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_70 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_622 (Conv1D)             (None, 500, 16)      816         input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_625 (Conv1D)             (None, 500, 32)      1632        input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_691 (LeakyReLU)     (None, 500, 16)      0           conv1d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_694 (LeakyReLU)     (None, 500, 32)      0           conv1d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_553 (Dropout)           (None, 500, 16)      0           leaky_re_lu_691[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_556 (Dropout)           (None, 500, 32)      0           leaky_re_lu_694[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_628 (Conv1D)             (None, 500, 64)      3264        input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_623 (Conv1D)             (None, 500, 16)      12816       dropout_553[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_626 (Conv1D)             (None, 500, 32)      51232       dropout_556[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_697 (LeakyReLU)     (None, 500, 64)      0           conv1d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_692 (LeakyReLU)     (None, 500, 16)      0           conv1d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_695 (LeakyReLU)     (None, 500, 32)      0           conv1d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_559 (Dropout)           (None, 500, 64)      0           leaky_re_lu_697[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_554 (Dropout)           (None, 500, 16)      0           leaky_re_lu_692[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_557 (Dropout)           (None, 500, 32)      0           leaky_re_lu_695[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_629 (Conv1D)             (None, 500, 64)      204864      dropout_559[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_624 (Conv1D)             (None, 500, 16)      12816       dropout_554[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_627 (Conv1D)             (None, 500, 32)      51232       dropout_557[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_698 (LeakyReLU)     (None, 500, 64)      0           conv1d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_693 (LeakyReLU)     (None, 500, 16)      0           conv1d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_696 (LeakyReLU)     (None, 500, 32)      0           conv1d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_630 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_698[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_555 (Dropout)           (None, 500, 16)      0           leaky_re_lu_693[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_558 (Dropout)           (None, 500, 32)      0           leaky_re_lu_696[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_699 (LeakyReLU)     (None, 500, 64)      0           conv1d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 500, 112)     0           dropout_555[0][0]                \n",
      "                                                                 dropout_558[0][0]                \n",
      "                                                                 leaky_re_lu_699[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 500, 112)     448         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_700 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_700[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 1904)         0           max_pooling1d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_560 (Dropout)           (None, 1904)         0           flatten_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 128)          243840      dropout_560[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 1)            129         dense_139[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 23s 2ms/step - loss: 1.9108 - binary_accuracy: 0.5633 - val_loss: 1.0247 - val_binary_accuracy: 0.6553\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 7s 581us/step - loss: 0.6791 - binary_accuracy: 0.6207 - val_loss: 0.7271 - val_binary_accuracy: 0.6343\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 7s 590us/step - loss: 0.6462 - binary_accuracy: 0.6346 - val_loss: 0.6948 - val_binary_accuracy: 0.6663\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 7s 585us/step - loss: 0.6289 - binary_accuracy: 0.6469 - val_loss: 0.7622 - val_binary_accuracy: 0.5778\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 7s 587us/step - loss: 0.6118 - binary_accuracy: 0.6624 - val_loss: 0.7511 - val_binary_accuracy: 0.5558\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.5991 - binary_accuracy: 0.6733 - val_loss: 0.7463 - val_binary_accuracy: 0.5023\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6398648648648648\n",
      "AUC is 0.6991042731921111\n",
      "F1-score is 0.6301179736294239\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_631 (Conv1D)             (None, 500, 16)      816         input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_634 (Conv1D)             (None, 500, 32)      1632        input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_701 (LeakyReLU)     (None, 500, 16)      0           conv1d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_704 (LeakyReLU)     (None, 500, 32)      0           conv1d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_561 (Dropout)           (None, 500, 16)      0           leaky_re_lu_701[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_564 (Dropout)           (None, 500, 32)      0           leaky_re_lu_704[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_637 (Conv1D)             (None, 500, 64)      3264        input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_632 (Conv1D)             (None, 500, 16)      12816       dropout_561[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_635 (Conv1D)             (None, 500, 32)      51232       dropout_564[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_707 (LeakyReLU)     (None, 500, 64)      0           conv1d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_702 (LeakyReLU)     (None, 500, 16)      0           conv1d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_705 (LeakyReLU)     (None, 500, 32)      0           conv1d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_567 (Dropout)           (None, 500, 64)      0           leaky_re_lu_707[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_562 (Dropout)           (None, 500, 16)      0           leaky_re_lu_702[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_565 (Dropout)           (None, 500, 32)      0           leaky_re_lu_705[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_638 (Conv1D)             (None, 500, 64)      204864      dropout_567[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_633 (Conv1D)             (None, 500, 16)      12816       dropout_562[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_636 (Conv1D)             (None, 500, 32)      51232       dropout_565[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_708 (LeakyReLU)     (None, 500, 64)      0           conv1d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_703 (LeakyReLU)     (None, 500, 16)      0           conv1d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_706 (LeakyReLU)     (None, 500, 32)      0           conv1d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_639 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_708[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_563 (Dropout)           (None, 500, 16)      0           leaky_re_lu_703[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_566 (Dropout)           (None, 500, 32)      0           leaky_re_lu_706[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_709 (LeakyReLU)     (None, 500, 64)      0           conv1d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 500, 112)     0           dropout_563[0][0]                \n",
      "                                                                 dropout_566[0][0]                \n",
      "                                                                 leaky_re_lu_709[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 500, 112)     448         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_710 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_710[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 1904)         0           max_pooling1d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_568 (Dropout)           (None, 1904)         0           flatten_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 128)          243840      dropout_568[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 1)            129         dense_141[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 24s 2ms/step - loss: 1.9938 - binary_accuracy: 0.5679 - val_loss: 0.8683 - val_binary_accuracy: 0.6408\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 7s 586us/step - loss: 0.6795 - binary_accuracy: 0.6312 - val_loss: 0.8442 - val_binary_accuracy: 0.6053\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 7s 589us/step - loss: 0.6414 - binary_accuracy: 0.6485 - val_loss: 0.7125 - val_binary_accuracy: 0.5633\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 7s 587us/step - loss: 0.6142 - binary_accuracy: 0.6665 - val_loss: 0.7942 - val_binary_accuracy: 0.5123\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.6105 - binary_accuracy: 0.6673 - val_loss: 0.7004 - val_binary_accuracy: 0.4857\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.5969 - binary_accuracy: 0.6740 - val_loss: 0.7205 - val_binary_accuracy: 0.5068\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 7s 595us/step - loss: 0.5843 - binary_accuracy: 0.6786 - val_loss: 0.7444 - val_binary_accuracy: 0.4857\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 7s 591us/step - loss: 0.5790 - binary_accuracy: 0.6877 - val_loss: 0.7826 - val_binary_accuracy: 0.4762\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6229729729729729\n",
      "AUC is 0.7129519722425128\n",
      "F1-score is 0.6840317100792752\n",
      "Accuracy:  62.02363410287466\n",
      "AUC:  0.6854946345062597\n",
      "f1-score:  0.564721788881774\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "f1_list = []\n",
    "loss = []\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train = Y[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # added flip of the training data\n",
    "#     extend_x = np.flip(X_train, axis=1)\n",
    "#     extend_y = Y_train\n",
    "\n",
    "#     X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "#     Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "    \n",
    "    print('Build model...')\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same')(inp)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=2)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=3)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=2)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=3)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(inp)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Dropout(dropout)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=2)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=3)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "    middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "    middle = BatchNorm()(middle)\n",
    "    middle = LeakyReLU(alpha=0.01)(middle)\n",
    "    middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "    middle = Flatten()(middle)\n",
    "    middle = Dropout(dropout)(middle)\n",
    "\n",
    "    out = Dense(128, activation='linear')(middle)\n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Train...\")\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                        validation_split=0.15)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, np.round(Y_pred))\n",
    "    print('Accuracy is', acc)\n",
    "    AUC = roc_auc_score(Y_test, Y_pred)\n",
    "    print('AUC is', AUC)\n",
    "    f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "    print('F1-score is', f1)\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    AUC_list.append(AUC)\n",
    "    f1_list.append(f1)\n",
    "    loss.append(np.mean(history.history['val_loss']))\n",
    "    \n",
    "print('Accuracy: ', np.mean(acc_list)*100)\n",
    "print('AUC: ', np.mean(AUC_list))\n",
    "print('f1-score: ', np.mean(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6689541251655038,\n",
       " 0.5953511412705957,\n",
       " 0.723737097421308,\n",
       " 0.5728106649159281,\n",
       " 0.7121329437545654,\n",
       " 0.7156482834185538,\n",
       " 0.7080204528853178,\n",
       " 0.7462353907962016,\n",
       " 0.6991042731921111,\n",
       " 0.7129519722425128]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
